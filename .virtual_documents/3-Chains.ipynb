from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.schema.output_parser import StrOutputParser
from langchain.schema.runnable import RunnableLambda, RunnableSequence


# api key
GOOGLE_API_KEY = 'AIzaSyA1JZtSuvWkn6S5UP0zgKVi698H2h2S0ww'
# create gemini-pro chat model 
model = ChatGoogleGenerativeAI(model='gemini-pro', google_api_key=GOOGLE_API_KEY)


# create prompt template to gide our model 
template = """Tell me {number} truths about {input}"""
prompt = PromptTemplate(input_variables=['number', 'input'], template=template)


# we can create any function using runnable lambda and add it to the sequence
# for example upper case the output
upper_case = RunnableLambda(lambda x: x.upper().strip())
# count number of words in your response
words_count = RunnableLambda(lambda x:f'Count of words: {len(x.split())} \n{x}') 
# Clean up ** (optional if needed)
cleanup = RunnableLambda(lambda x: x.replace("**", ""))


# create chain 
chain = prompt | model | StrOutputParser() | cleanup | upper_case | words_count


response = chain.invoke({'number': 3, 'input': 'llms'})
print(response)



