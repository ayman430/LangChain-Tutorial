{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "739c1c48-7811-489b-92dc-c3e94b140a47",
   "metadata": {},
   "source": [
    "## Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9de0719-2c7e-4ad3-bdbf-e945a59b19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8b4a06-aed3-4226-8879-331ca0d69f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "GOOGLE_API_KEY = 'AIzaSyA1JZtSuvWkn6S5UP0zgKVi698H2h2S0ww'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b45dc9-b17e-4447-b4db-42505151ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create gemini-pro chat model \n",
    "model = ChatGoogleGenerativeAI(model='gemini-pro', google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b8cf5-80bf-40c7-bc8c-aa493f181a8c",
   "metadata": {},
   "source": [
    "## Create Simple prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e289de-1f30-42a1-8861-d10c8083e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d210788-c53c-4877-a210-30fe64b0d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template to gide our model \n",
    "template = \"\"\"Tell me {number} truths about {input}\"\"\"\n",
    "prompt = PromptTemplate(input_variables=['number', 'input'], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d275b1e-b646-4b65-b3ba-d77387111d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me 3 truths about cat'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give a value  for prompt input \n",
    "num = 3\n",
    "user_input = 'cat'\n",
    "promptValue = prompt.format(number=num, input=user_input)\n",
    "promptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73c9d6fe-236d-4a9f-a955-830675599eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Cats have excellent night vision, thanks to a reflective layer in their eyes called the tapetum lucidum.\n",
      "2. Cats have a unique organ called the Jacobson's organ, which allows them to detect pheromones and other scents that are invisible to humans.\n",
      "3. Cats are obligate carnivores, meaning that they must eat meat to survive.\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(promptValue)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2984b67-15f2-4341-8ad7-8711ec55a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13192451-2005-4036-8810-44cbdf5a0b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarize the text delimited by triple backticks \\ \n",
      "into a single sentence.\n",
      "```\n",
      "You should express what you want a model to do by \\ \n",
      "providing instructions that are as clear and \\ \n",
      "specific as you can possibly make them. \\ \n",
      "This will guide the model towards the desired output, \\ \n",
      "and reduce the chances of receiving irrelevant \\ \n",
      "or incorrect responses. Don't confuse writing a \\ \n",
      "clear prompt with writing a short prompt. \\ \n",
      "In many cases, longer prompts provide more clarity \\ \n",
      "and context for the model, which can lead to \\ \n",
      "more detailed and relevant outputs.\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(input_variables=['text'], template=prompt)\n",
    "promptValue = prompt.format(text=text)\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e6349-1b9f-4d4a-beeb-ca9e835b47d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
