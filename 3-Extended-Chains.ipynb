{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7db2e511-8bfe-4a41-8aa3-c9c40418c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc233000-a452-4d09-b075-d61c7987b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "GOOGLE_API_KEY = 'AIzaSyA1JZtSuvWkn6S5UP0zgKVi698H2h2S0ww'\n",
    "# create gemini-pro chat model \n",
    "model = ChatGoogleGenerativeAI(model='gemini-pro', google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52df8abc-757c-4e5a-8853-27f211f8d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template to gide our model \n",
    "template = \"\"\"Tell me {number} truths about {input}\"\"\"\n",
    "prompt = PromptTemplate(input_variables=['number', 'input'], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49c13687-4e7c-4fff-92f3-6b852622cadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can create any function using runnable lambda and add it to the sequence\n",
    "# for example upper case the output\n",
    "upper_case = RunnableLambda(lambda x: x.upper().strip())\n",
    "# count number of words in your response\n",
    "words_count = RunnableLambda(lambda x:f'Count of words: {len(x.split())} \\n{x}') \n",
    "# Clean up ** (optional if needed)\n",
    "cleanup = RunnableLambda(lambda x: x.replace(\"**\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b10edfaa-5d69-4912-b718-8840c2af2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chain \n",
    "chain = prompt | model | StrOutputParser() | cleanup | upper_case | words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35d77a40-9fde-4c88-be88-2e79ffb474ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of words: 111 \n",
      "1. LLMS ARE POWERFUL LANGUAGE MODELS TRAINED ON MASSIVE DATASETS: LLMS (LARGE LANGUAGE MODELS) ARE TRAINED ON VAST CORPORA OF TEXT AND CODE, GIVING THEM A COMPREHENSIVE UNDERSTANDING OF LANGUAGE AND ITS NUANCES.\n",
      "2. LLMS CAN GENERATE HUMAN-LIKE TEXT AND CODE: LLMS POSSESS THE ABILITY TO CREATE COHERENT, GRAMMATICALLY CORRECT, AND CONTEXTUALLY RELEVANT TEXT AND CODE, MAKING THEM CAPABLE OF TASKS SUCH AS STORY WRITING, SUMMARIZATION, AND CODE GENERATION.\n",
      "3. LLMS HAVE LIMITATIONS AND BIASES: WHILE LLMS ARE REMARKABLY PROFICIENT IN MANY LANGUAGE-RELATED TASKS, THEY ARE NOT WITHOUT LIMITATIONS. THEY CAN SOMETIMES GENERATE BIASED OR FACTUALLY INACCURATE CONTENT, AND THEIR PERFORMANCE CAN VARY DEPENDING ON THE INPUT DATA AND TASK COMPLEXITY.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'number': 3, 'input': 'llms'})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c924d7-2cb8-4d21-b23a-ba8ac1d27ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
